{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xKg4v-zNs748","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743006617200,"user_tz":240,"elapsed":25298,"user":{"displayName":"Victoria Brendel","userId":"09422268440750723140"}},"outputId":"f9a19d4e-2fbc-47fa-b87c-176289697a26"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","#!pip install --upgrade openai\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"4TLz0QYbxClf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743006730640,"user_tz":240,"elapsed":113451,"user":{"displayName":"Victoria Brendel","userId":"09422268440750723140"}},"outputId":"664aba1f-f131-46b4-e688-786a12e031c0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q transformers accelerate bitsandbytes\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oVdUS4BWs7R2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743006738829,"user_tz":240,"elapsed":8210,"user":{"displayName":"Victoria Brendel","userId":"09422268440750723140"}},"outputId":"df82e305-4551-418d-daa4-a670eb20efc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["🟡 Original Tweet:\n","I can’t believe how fast this year is flying by 😩\n","\n","🟢 Paraphrased by DeepSeek:\n","\"Wow, this year is zooming by way too quickly 😫\"  \n","\n","Let me know if you'd like any adjustments!\n"]}],"source":["from openai import OpenAI\n","from google.colab import userdata\n","\n","# Initialize DeepSeek client\n","deepseek_client = OpenAI(\n","    base_url='https://api.deepseek.com',\n","    api_key=userdata.get(\"DEEPSEEK_API_KEY\")\n",")\n","\n","# Sample tweet to test\n","sample_tweet = \"I can’t believe how fast this year is flying by 😩\"\n","\n","# Construct prompt\n","system_message = \"You are a helpful assistant that rephrases tweets using different words while keeping the tone and meaning intact.\"\n","prompt = [\n","    {\"role\": \"system\", \"content\": system_message},\n","    {\"role\": \"user\", \"content\": f'Paraphrase this tweet: \"{sample_tweet}\"'}\n","]\n","\n","# Make API call\n","response = deepseek_client.chat.completions.create(\n","    model=\"deepseek-chat\",\n","    messages=prompt,\n","    max_tokens=60\n",")\n","\n","# Extract the result\n","paraphrased = response.choices[0].message.content.strip()\n","\n","# Show it\n","print(\"🟡 Original Tweet:\")\n","print(sample_tweet)\n","print(\"\\n🟢 Paraphrased by DeepSeek:\")\n","print(paraphrased)\n"]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load your original tweet dataset\n","column_names = ['target','ids','date','flag','user','text']\n","df = pd.read_csv(\"/content/drive/MyDrive/fp/training.1600000.processed.noemoticon.csv\", encoding='latin-1', names=column_names)\n","\n","# Reproduce the original shuffling (random_state=42)\n","df_sampled = df.sample(frac=1, random_state=42).reset_index(drop=True)\n","\n","# Extract your GPT chunk (middle third)\n","chunk_3 = df_sampled.iloc[60000:90000].copy()\n"],"metadata":{"id":"WpPGg5jpmhGZ","executionInfo":{"status":"ok","timestamp":1743006755845,"user_tz":240,"elapsed":16990,"user":{"displayName":"Victoria Brendel","userId":"09422268440750723140"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"FwOUAq-7_ciN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743006761353,"user_tz":240,"elapsed":5478,"user":{"displayName":"Victoria Brendel","userId":"09422268440750723140"}},"outputId":"f7cbaa22-4a75-4c28-b432-9d7d3d04c964"},"outputs":[{"output_type":"stream","name":"stdout","text":["🟡 Original Tweet:\n","I can’t believe how fast this year is flying by 😩\n","\n","🟢 Paraphrased by DeepSeek:\n","\"Time is zooming by way too quickly this year 😫\"  \n","\n","Let me know if you'd like any adjustments!\n"]}],"source":["from openai import OpenAI\n","from google.colab import userdata\n","\n","# Initialize DeepSeek client\n","deepseek_client = OpenAI(\n","    base_url='https://api.deepseek.com',\n","    api_key=userdata.get(\"DEEPSEEK_API_KEY\")\n",")\n","\n","# Sample tweet to test\n","sample_tweet = \"I can’t believe how fast this year is flying by 😩\"\n","\n","# Construct prompt\n","system_message = \"You are a helpful assistant that rephrases tweets using different words while keeping the tone and meaning intact.\"\n","prompt = [\n","    {\"role\": \"system\", \"content\": system_message},\n","    {\"role\": \"user\", \"content\": f'Paraphrase this tweet: \"{sample_tweet}\"'}\n","]\n","\n","# Make API call with max_tokens = 40\n","response = deepseek_client.chat.completions.create(\n","    model=\"deepseek-chat\",\n","    messages=prompt,\n","    max_tokens=40  # ✅ updated here\n",")\n","\n","# Extract the result\n","paraphrased = response.choices[0].message.content.strip()\n","\n","# Show it\n","print(\"🟡 Original Tweet:\")\n","print(sample_tweet)\n","print(\"\\n🟢 Paraphrased by DeepSeek:\")\n","print(paraphrased)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4qtMl73lBd4n","outputId":"c269cf45-ce6d-41fc-d068-750ad8f87493"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 72%|███████▏  | 21617/30000 [09:40<14:34:45,  6.26s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 21617\n"]},{"output_type":"stream","name":"stderr","text":[" 72%|███████▏  | 21717/30000 [19:14<12:49:11,  5.57s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 21717\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 21817/30000 [28:49<13:20:53,  5.87s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 21817\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 21917/30000 [38:09<12:28:18,  5.55s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 21917\n"]},{"output_type":"stream","name":"stderr","text":[" 73%|███████▎  | 22017/30000 [47:51<12:10:50,  5.49s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 22017\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▎  | 22117/30000 [57:19<13:17:33,  6.07s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 22117\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 22217/30000 [1:06:38<12:10:15,  5.63s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 22217\n"]},{"output_type":"stream","name":"stderr","text":[" 74%|███████▍  | 22317/30000 [1:16:03<11:38:25,  5.45s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 22317\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 22417/30000 [1:25:26<11:32:33,  5.48s/it]"]},{"output_type":"stream","name":"stdout","text":["💾 Saved batch of 100 tweets at index 22417\n"]},{"output_type":"stream","name":"stderr","text":[" 75%|███████▍  | 22466/30000 [1:29:58<11:20:24,  5.42s/it]"]}],"source":["from openai import OpenAI\n","from google.colab import userdata\n","import os, json\n","from tqdm import tqdm\n","\n","# ✅ Initialize DeepSeek client\n","deepseek_client = OpenAI(\n","    base_url='https://api.deepseek.com',\n","    api_key=userdata.get(\"DEEPSEEK_API_KEY\")\n",")\n","\n","# ✅ Configs\n","system_message = \"You are a helpful assistant that rephrases tweets using different words while keeping the tone and meaning intact.\"\n","prompt_prefix = \"Paraphrase this tweet: \"\n","max_tokens = 40\n","batch_size = 100\n","\n","# ✅ File paths\n","save_dir = \"/content/drive/MyDrive/fp/deepseek_outputs/\"\n","os.makedirs(save_dir, exist_ok=True)\n","output_file = os.path.join(save_dir, \"chunk3_deepseek_paraphrased.jsonl\")\n","index_file = os.path.join(save_dir, \"chunk3_processed_indices.txt\")\n","\n","# ✅ Load progress\n","if os.path.exists(index_file):\n","    with open(index_file, \"r\") as f:\n","        processed = set(map(int, f.read().splitlines()))\n","else:\n","    processed = set()\n","\n","# ✅ Batch variables\n","batch = []\n","batch_indices = []\n","\n","# ✅ Process in batches\n","for idx, row in enumerate(tqdm(chunk_3.itertuples(), total=len(chunk_3))):\n","    if idx in processed:\n","        continue\n","\n","    tweet = row.text.strip()\n","\n","    messages = [\n","        {\"role\": \"system\", \"content\": system_message},\n","        {\"role\": \"user\", \"content\": f'{prompt_prefix}\"{tweet}\"'}\n","    ]\n","\n","    try:\n","        response = deepseek_client.chat.completions.create(\n","            model=\"deepseek-chat\",\n","            messages=messages,\n","            max_tokens=max_tokens\n","        )\n","        paraphrased = response.choices[0].message.content.strip()\n","\n","        batch.append({\n","            \"id\": idx,\n","            \"original\": tweet,\n","            \"paraphrased\": paraphrased\n","        })\n","        batch_indices.append(idx)\n","\n","    except Exception as e:\n","        print(f\"❌ Error on idx {idx}: {e}\")\n","        continue\n","\n","    # ✅ Save every 100 tweets\n","    if len(batch) == batch_size:\n","        with open(output_file, \"a\") as fout:\n","            for item in batch:\n","                fout.write(json.dumps(item) + \"\\n\")\n","\n","        with open(index_file, \"a\") as fidx:\n","            for index in batch_indices:\n","                fidx.write(f\"{index}\\n\")\n","\n","        print(f\"💾 Saved batch of {batch_size} tweets at index {idx + 1}\")\n","\n","        # Reset batch\n","        batch = []\n","        batch_indices = []\n","\n","# ✅ Save remaining tweets (if any)\n","if batch:\n","    with open(output_file, \"a\") as fout:\n","        for item in batch:\n","            fout.write(json.dumps(item) + \"\\n\")\n","\n","    with open(index_file, \"a\") as fidx:\n","        for index in batch_indices:\n","            fidx.write(f\"{index}\\n\")\n","\n","    print(f\"💾 Saved final batch of {len(batch)} tweets\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rghLFy54Bls3"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOvz4F3RTBNWIacllYpvDMw"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}